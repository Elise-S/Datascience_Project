{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Named Entity Recognition"
      ],
      "metadata": {
        "id": "zqzEsJUfHU-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function that will process one document (i.e. a biography)\n",
        "and return the set of named entities (NE) detected within it. Do\n",
        "this for both Spacy and Stanza. Store your results where (e.g.\n",
        "Pandas dataframe/json file) you can easily retrieve them to do\n",
        "comparisons."
      ],
      "metadata": {
        "id": "zZMHybRMHW4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   avg/min/max number of NEs. Report this per category per\n",
        "package.\n",
        "\n",
        "2. avg/min/max number of words in each NE. Report this per category per package\n",
        "\n",
        "4.   Use visualisation to compare the above 2 statistics, per category\n",
        "per package\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xhwukDDqXsO-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   SPACY\n",
        "\n"
      ],
      "metadata": {
        "id": "1j-BSJhkJQXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.language import Language"
      ],
      "metadata": {
        "id": "b9yVZ6kxJjSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yHN_95PGfoz"
      },
      "outputs": [],
      "source": [
        "from spacy.pipeline import EntityRecognizer\n",
        "import pandas as pd\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(EntityRecognizer.labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zl1rQPMcJsKW",
        "outputId": "00375f58-30c5-438d-99eb-46a51f2da121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<attribute 'labels' of 'spacy.pipeline.ner.EntityRecognizer' objects>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_entities(biography_text):\n",
        "\n",
        "    doc = nlp(biography_text)# Process the  text by using the loaded SpaCy model\n",
        "    entities = [(ent.text, ent.label_) for ent in doc.ents]# this will extract the  NE and their labels\n",
        "    df = pd.DataFrame(entities, columns=['Entity', 'Label'])# the dataset wil have entity and label collums\n",
        "    entity_counts = df['Label'].value_counts() # Calculate the number of named entities per category so by label\n",
        "    stats = {\n",
        "        'num_entities': {\n",
        "            'avg': entity_counts.mean(),\n",
        "            'min': entity_counts.min(),\n",
        "            'max': entity_counts.max()}}\n",
        "\n",
        "    df['num_words'] = df['Label'].apply(lambda x: len(x.split())) # Calculate the number of words in each named entity\n",
        "    word_counts = df.groupby('Entity')['num_words'].agg(['mean', 'min', 'max']) # Calculate word count statistics per category\n",
        "\n",
        "    return df, stats"
      ],
      "metadata": {
        "id": "S_gERjL0Jzk7"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aQ6sFJUAk9Um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# do a try\n",
        "text = open(\"webnlg-test.txt\", \"r\")\n",
        "textContent = text.read()\n",
        "sp_doc = nlp(textContent)\n",
        "get_entities(sp_doc)\n",
        "#print (df)\n",
        "#print (stats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v9Z_xotTtcy",
        "outputId": "8706a62f-4b32-422a-e050-77e3f06e4e02"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                  Entity        Label  num_words\n",
              " 0                        da Mata Fonseca       PERSON          1\n",
              " 1      Agremiação Sportiva Arapiraquense          ORG          1\n",
              " 2                              Arapiraca       PERSON          1\n",
              " 3      Agremiação Sportiva Arapiraquense       PERSON          1\n",
              " 4                              Alvinegro  WORK_OF_ART          1\n",
              " ...                                  ...          ...        ...\n",
              " 20861      the Pacific Standard Daylight          LOC          1\n",
              " 20862                       Ciudad Ayala       PERSON          1\n",
              " 20863                             Mexico          GPE          1\n",
              " 20864     the Pacific Standard Time Zone          LOC          1\n",
              " 20865              Pacific Daylight Time          LOC          1\n",
              " \n",
              " [20866 rows x 3 columns],\n",
              " {'num_entities': {'avg': 1159.2222222222222, 'min': 8, 'max': 5538}})"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fwn56FQzXHj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TRY ONE\n",
        "\n",
        "#def get_entities(biography_text):\n",
        "    #text = open(biography_text, \"r\")\n",
        "    #docContent = text.read()\n",
        "    #docContent = nlp(biography_text)# Process the  text by using the loaded SpaCy model\n",
        "    #entities = [(ent.text, ent.label_) for ent in docContent.ents]# this will extract the  NE and their labels\n",
        "    #df = pd.DataFrame(entities, columns=['Entity', 'Label'])\n",
        "\n",
        "    #return df"
      ],
      "metadata": {
        "id": "W9JjoNUqabtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "1hMVJPWqO33X",
        "outputId": "43bd0efe-4fad-4dce-f490-797650f62bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'spacy.tokens.doc.Doc' object has no attribute 'head'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-040cfc10053e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msp_doc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.doc.Doc' object has no attribute 'head'"
          ]
        }
      ]
    }
  ]
}